import base64
import io
import logging

import aiohttp
from app.core.broker import broker
from app.core.config import settings
from app.core.database import engine
from app.core.logging import setup_logging
from app.db.models.trigger import ModerationStatus, Trigger
from app.schemas.moderation import ModerationAlert, ModerationLLMResult, TriggerModerationTask
from faststream import FastStream
from PIL import Image
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker

setup_logging()
logger = logging.getLogger(__name__)

app = FastStream(broker)

# Session maker for worker
async_session = async_sessionmaker(engine, expire_on_commit=False)


async def get_telegram_file_url(file_id: str) -> str | None:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ URL Ñ„Ð°Ð¹Ð»Ð° Ð¸Ð· Telegram."""
    async with aiohttp.ClientSession() as session:
        url = f"https://api.telegram.org/bot{settings.BOT_TOKEN}/getFile?file_id={file_id}"
        if settings.TELEGRAM_BOT_API_URL:
            url = f"{settings.TELEGRAM_BOT_API_URL}/bot{settings.BOT_TOKEN}/getFile?file_id={file_id}"

        async with session.get(url) as response:
            if response.status != 200:
                logger.error(f"Failed to get file info: {response.status}")
                return None
            data = await response.json()
            if not data.get("ok"):
                logger.error(f"Telegram API error: {data}")
                return None

            file_path = data["result"]["file_path"]

            if settings.TELEGRAM_BOT_API_URL:
                return f"{settings.TELEGRAM_BOT_API_URL}/file/bot{settings.BOT_TOKEN}/{file_path}"
            return f"https://api.telegram.org/file/bot{settings.BOT_TOKEN}/{file_path}"


async def download_file(url: str) -> bytes | None:
    """Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð»."""
    async with aiohttp.ClientSession() as session, session.get(url) as response:
        if response.status != 200:
            logger.error(f"Failed to download file: {response.status}")
            return None
        return await response.read()


def resize_image(image_data: bytes, max_size: int = 512) -> bytes:
    """Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¾ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ðµ."""
    try:
        image = Image.open(io.BytesIO(image_data))

        # Convert to RGB if necessary (e.g. for RGBA or P mode)
        if image.mode in ("RGBA", "P"):
            image = image.convert("RGB")

        if max(image.size) > max_size:
            image.thumbnail((max_size, max_size))
            output = io.BytesIO()
            image.save(output, format="JPEG", quality=85)
            return output.getvalue()
        return image_data
    except Exception as e:
        logger.error(f"Failed to resize image: {e}")
        return image_data


async def unload_unknown_models() -> None:
    """Ð’Ñ‹Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð±Ð¾Ñ‚Ð¾Ð¼."""
    known_models = {
        settings.OLLAMA_VISION_MODEL if hasattr(settings, "OLLAMA_VISION_MODEL") else "llava:7b",
        settings.OLLAMA_TEXT_MODEL if hasattr(settings, "OLLAMA_TEXT_MODEL") else "aya-expanse:8b",
    }

    async with aiohttp.ClientSession() as session:
        try:
            # 1. Get running models
            async with session.get(f"{settings.OLLAMA_BASE_URL}/api/ps") as response:
                if response.status != 200:
                    logger.error(f"Failed to list models: {response.status}")
                    return
                data = await response.json()
                running_models = data.get("models", [])

            # 2. Unload unknown models
            for model in running_models:
                model_name = model.get("name")
                # If the running model is NOT in known_models, unload it.
                if model_name not in known_models:
                    logger.info(f"Unloading unknown model: {model_name}")
                    unload_payload = {"model": model_name, "keep_alive": 0}
                    async with session.post(
                        f"{settings.OLLAMA_BASE_URL}/api/generate", json=unload_payload
                    ) as unload_response:
                        if unload_response.status != 200:
                            logger.error(f"Failed to unload model {model_name}: {unload_response.status}")
        except Exception as e:
            logger.error(f"Failed to manage models: {e}")


async def call_vision_model(image_data: bytes) -> str:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¾Ñ‚ Vision Ð¼Ð¾Ð´ÐµÐ»Ð¸."""
    # Resize image to reduce load
    resized_image_data = resize_image(image_data)
    b64_image = base64.b64encode(resized_image_data).decode("utf-8")

    prompt = (
        "Analyze this image strictly for content moderation. Provide a detailed objective description. "
        "Focus your attention on these specific risk indicators:\n\n"
        "1. DRUG TRADE SIGNS:\n"
        "   - Substances: Powders, crystals, pills, cannabis buds.\n"
        "   - Paraphernalia: Syringes, precision scales, bongs, glass pipes.\n"
        "   - Packaging: Small ziplock bags, bundles wrapped in colored electrical tape or foil (typical for 'dead drops/klads'), magnetic boxes.\n\n"  # noqa: E501
        "2. RECRUITMENT & ADVERTISING (SCAM):\n"
        "   - Street Graffiti/Stencils: Look for spray-painted text on walls/pavements containing @usernames, URLs, or keywords like 'rabota', 'sk', 'shish', 'z.', 'zp'.\n"  # noqa: E501
        "   - Screenshots: Text conversations about 'easy money', 'deliveries', or 'walking jobs'.\n"
        "   - QR Codes: Any visible QR codes or barcodes.\n\n"
        "3. PORNOGRAPHY:\n"
        "   - Explicit nudity, genitalia, sexual acts, or highly suggestive poses.\n\n"
        "CRITICAL INSTRUCTION: Transcribe ALL visible text verbatim, especially text overlays, "
        "handwritten notes, or graffiti. If text is in Russian or slang, transcribe it exactly as is."
    )

    model = settings.OLLAMA_VISION_MODEL if hasattr(settings, "OLLAMA_VISION_MODEL") else "qwen3-vl:8b"

    await unload_unknown_models()

    payload = {
        "model": model,
        "prompt": prompt,
        "images": [b64_image],
        "stream": False,
        "options": {
            "temperature": 0.2,
            "num_predict": 512,
            "top_k": 10,
            "top_p": 0.9,
        },
    }

    async with aiohttp.ClientSession() as session:
        for attempt in range(3):
            try:
                async with session.post(f"{settings.OLLAMA_BASE_URL}/api/generate", json=payload) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"Ollama Vision ({model}) error: {response.status}, body: {error_text}")
                        if response.status >= 500:
                            # Retry on server errors
                            continue
                        return ""
                    data = await response.json()
                    result = data.get("response", "")

                    # Check for broken output
                    if "<unk>" in result:
                        logger.warning(f"Ollama returned <unk> tokens: {result}")
                        if attempt < 2:
                            continue
                        return ""

                    return result
            except Exception as e:
                logger.error(f"Failed to call Ollama Vision (attempt {attempt + 1}): {e}")
                if attempt == 2:
                    return ""
    return ""


async def call_moderation_model(text_content: str, caption: str, image_description: str) -> ModerationLLMResult | None:
    """ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ LLM."""

    system_prompt = (
        "You are a specialized content moderation AI. Analyze the provided user content "
        "(text, image caption, and visual description) to detect illegal goods and recruitment.\n"
        "Your goal is to classify content into STRICTLY one of these categories: "
        '"Drugs", "Porn", "Scam", or "Safe".\n\n'
        "Priority Instructions:\n"
        "1. Look for obfuscated language, emojis (e.g., â„ï¸, ðŸ¬, ðŸŒ¿), and slang used in drug trade.\n"
        "2. Differentiate between general spam and specific recruitment for illegal work.\n\n"
        "Definitions for Classification:\n"
        "ðŸ”´ Drugs: Content related to the DIRECT SALE, advertising, or promotion of illegal substances.\n"
        "   - Includes: Price lists, 'shop' links, photos of substances with intent to sell, specific strain names/prices.\n"  # noqa: E501
        "   - Excludes: News, educational, or scientific discussion about drugs without promotion.\n\n"
        "ðŸ”ž Porn: Explicit sexual content.\n"
        "   - Includes: Visible genitalia, sexual acts, masturbation, pornographic intent/links.\n"
        "   - Excludes: Artistic nudity (statues), medical context (unless explicit).\n\n"
        "âš ï¸ Scam (Drug Recruitment Focus): Content recruiting people for illegal distribution roles.\n"
        "   - Keywords/Concepts: 'High salary no experience', 'courier', 'delivery job', 'easy money', 'graffiti job', "
        "'warehouse worker', 'walking around the city'.\n"
        "   - Focus: Job offers that imply becoming a 'dropper' (kladmen) or money mule.\n\n"
        "âœ… Safe: Content that clearly does NOT fit the above categories.\n\n"
        "Output MUST be a valid JSON object with this exact structure:\n"
        "{\n"
        '  "category": "Drugs" | "Porn" | "Scam" | "Safe",\n'
        '  "confidence": float between 0.0 and 1.0,\n'
        '  "reasoning": "short explanation in English focusing on detected keywords or visual cues"\n'
        "}"
    )

    user_content = (
        f"User Text: {text_content or 'No text provided'}\n"
        f"Image Caption: {caption or 'No caption'}\n"
        f"Image Visual Description: {image_description or 'No image'}"
    )

    model = settings.OLLAMA_TEXT_MODEL if hasattr(settings, "OLLAMA_TEXT_MODEL") else "aya-expanse:8b"

    await unload_unknown_models()

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ],
        "format": "json",
        "stream": False,
        "options": {"temperature": 0.1},
    }

    async with aiohttp.ClientSession() as session:
        try:
            async with session.post(f"{settings.OLLAMA_BASE_URL}/api/chat", json=payload) as response:
                if response.status != 200:
                    logger.error(f"Ollama Moderation ({model}) error: {response.status}")
                    return None
                data = await response.json()
                content = data.get("message", {}).get("content", "")

                try:
                    return ModerationLLMResult.model_validate_json(content)
                except Exception as e:
                    logger.error(f"Failed to parse Moderation response: {content}, error: {e}")
                    return None
        except Exception as e:
            logger.error(f"Failed to call Ollama Moderation: {e}")
            return None


async def process_image(task: TriggerModerationTask) -> str:
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ."""
    if not (task.file_id and task.file_type in ["photo", "video", "animation", "document"]):
        return ""

    file_url = await get_telegram_file_url(task.file_id)
    if not file_url:
        return ""

    file_data = await download_file(file_url)
    if not file_data:
        return ""

    # Only send to Vision Model if it's an image.
    if task.file_type == "photo":
        description = await call_vision_model(file_data)
        logger.info(f"Image description: {description}")
        return description

    return ""


async def handle_moderation_result(session: AsyncSession, trigger: Trigger, result: ModerationLLMResult | None) -> None:
    """ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ Ñ‚Ñ€Ð¸Ð³Ð³ÐµÑ€Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° Ð¼Ð¾Ð´ÐµÑ€Ð°Ñ†Ð¸Ð¸."""
    if not result:
        # Error case
        trigger.moderation_status = ModerationStatus.FLAGGED
        trigger.moderation_reason = "AI Error"
        await session.commit()

        # Send alert
        alert = ModerationAlert(
            trigger_id=trigger.id,
            chat_id=trigger.chat_id,
            category="Error",
            reasoning="AI failed to process",
        )
        await broker.publish(alert, "q.moderation.alerts")
        return

    if result.category == "Safe":
        trigger.moderation_status = ModerationStatus.SAFE
        trigger.moderation_reason = "Safe"
        await session.commit()
        logger.info(f"Trigger {trigger.id} marked as Safe. Reasoning: {result.reasoning}")
    else:
        trigger.moderation_status = ModerationStatus.FLAGGED
        trigger.moderation_reason = result.category
        await session.commit()

        # Publish Alert
        alert = ModerationAlert(
            trigger_id=trigger.id,
            chat_id=trigger.chat_id,
            category=result.category,
            confidence=result.confidence,
            reasoning=result.reasoning,
        )
        await broker.publish(alert, "q.moderation.alerts")
        logger.info(f"Trigger {trigger.id} flagged as {result.category}. Reasoning: {result.reasoning}")


@broker.subscriber("q.moderation.analyze")
async def analyze_trigger(task: TriggerModerationTask) -> None:
    logger.info(f"Analyzing trigger {task.trigger_id} from chat {task.chat_id}")

    # 1. Process Image (if any)
    image_description = await process_image(task)

    # 2. Call Moderation Model
    result = await call_moderation_model(task.text_content, task.caption, image_description)

    # 3. Update Database
    async with async_session() as session:
        trigger = await session.get(Trigger, task.trigger_id)
        if not trigger:
            logger.warning(f"Trigger {task.trigger_id} not found")
            return

        await handle_moderation_result(session, trigger, result)
